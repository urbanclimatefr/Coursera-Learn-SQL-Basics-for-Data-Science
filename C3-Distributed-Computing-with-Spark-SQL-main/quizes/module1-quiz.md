1. Which of the following are true when it comes to the business value of big data? (Select all that apply.)

- Businesses are increasingly making data-driven decisions

- The size of the data businesses collect is growing

2. Spark uses...(Select all that apply.)

- A distributed cluster of networked computers made of a driver node and many executor nodes

- A driver node to distribute work across a number of executor nodes

3. How does Spark execute code backed by DataFrames? (Select all that apply.)

- It separates the "logical plan" of what you want to accomplish from the "physical plan" of how to do it so it can optimize the query

- It optimizes your query by figuring out the best "how" to execute what you want

4. What are the properties of Spark DataFrames? (Select all that apply.)

- Resilient: Fault-tolerant

- Distributed: Computed across multiple nodes

- Dataset: Collection of partitioned data

5. What is the difference between Spark and database technologies? (Select all that apply.)

- Spark is a highly optimized compute engine and is not a database

- Spark is a computation engine and is not for data storage

6. What is Amdahl's law of scalability? (Select all that apply.)

- Amdahl's law states that the speedup of a task is a function of how much of that task can be parallelized

- A formula that gives the theoretical speedup as a function of the percentage of a computation that can be parallelized

7. Spark offers a unified approach to analytics. What does this include? (Select all that apply.)

- Spark code can be written in the following languages: SQL, Scala, Java, Python, and R

- Spark is able to connect to data where it lives in any number of sources, unifying the components of a data application

- Spark allows analysts, data scientist, and data engineers to all use the same core technology

- Spark unities applications such as SQL queries, streaming, and machine learning

8. What is a Databricks notebook?

- A collaborative, interactive workspace that allows you to execute Spark queries at scale

9. How can you get data into Databricks? (Select all that apply.)

- By uploading it through the user interface

- By "mounting" data backed by cloud storage

- By registering the data as a table

10. What are the qualities of big data? (Select all that apply.)

- Volume

- Velocity

- Veracity

- Variety